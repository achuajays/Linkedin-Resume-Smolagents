{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install smolagents"
      ],
      "metadata": {
        "id": "gQBwOrLAes4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install litellm"
      ],
      "metadata": {
        "id": "EyDgBbHFfmrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "id": "ArhSjd0Gt01D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import LiteLLMModel\n",
        "\n",
        "model = LiteLLMModel(\n",
        "    \"gemini/gemini-2.0-flash\",\n",
        "    temperature=0.2,\n",
        "    api_key=\"Gemini_api_key\",\n",
        "    max_token = 8000\n",
        ")"
      ],
      "metadata": {
        "id": "vqmwsp9bggnE"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import Tool\n",
        "import requests\n",
        "\n",
        "class LinkedInProfileScraperTool(Tool):\n",
        "    name = \"linkedin_profile_scraper\"\n",
        "    description = \"Scrapes LinkedIn profile data using the Fresh LinkedIn Profile Data API from RapidAPI.\"\n",
        "\n",
        "    inputs = {\n",
        "        \"linkedin_url\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The LinkedIn profile URL to scrape (e.g., 'https://www.linkedin.com/in/username').\"\n",
        "        },\n",
        "        \"include_flags\": {\n",
        "            \"type\": \"object\",\n",
        "            \"description\": \"Optional dictionary of flags to include specific sections (e.g., {'include_skills': 'true'}).\",\n",
        "            \"default\": None,\n",
        "            \"nullable\": True  # Allow None as a valid value\n",
        "        }\n",
        "    }\n",
        "\n",
        "    output_type = \"string\"\n",
        "\n",
        "    def __init__(self, api_key, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.api_url = \"https://fresh-linkedin-profile-data.p.rapidapi.com/get-linkedin-profile-by-salesnavurl\"\n",
        "        self.headers = {\n",
        "            \"x-rapidapi-key\": api_key,\n",
        "            \"x-rapidapi-host\": \"fresh-linkedin-profile-data.p.rapidapi.com\"\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, linkedin_url: str, include_flags: dict = None):\n",
        "        \"\"\"\n",
        "        Scrape LinkedIn profile data from the provided URL using the Fresh LinkedIn Profile Data API.\n",
        "\n",
        "        Args:\n",
        "            linkedin_url (str): The LinkedIn profile URL to scrape.\n",
        "            include_flags (dict, optional): Flags to include specific sections (e.g., {'include_skills': 'true'}).\n",
        "\n",
        "        Returns:\n",
        "            str: The scraped profile data as a string or an error message.\n",
        "        \"\"\"\n",
        "        # Construct the query parameters\n",
        "        querystring = {\"linkedin_url\": linkedin_url}\n",
        "\n",
        "        # Default all sections to \"false\" unless overridden by include_flags\n",
        "        default_flags = {\n",
        "            \"include_skills\": \"false\",\n",
        "            \"include_certifications\": \"false\",\n",
        "            \"include_publications\": \"false\",\n",
        "            \"include_honors\": \"false\",\n",
        "            \"include_volunteers\": \"false\",\n",
        "            \"include_projects\": \"false\",\n",
        "            \"include_patents\": \"false\",\n",
        "            \"include_courses\": \"false\",\n",
        "            \"include_organizations\": \"false\"\n",
        "        }\n",
        "\n",
        "        # Update with user-provided flags if any\n",
        "        if include_flags:\n",
        "            default_flags.update(include_flags)\n",
        "\n",
        "        querystring.update(default_flags)\n",
        "\n",
        "        try:\n",
        "            # Send the GET request to the RapidAPI endpoint\n",
        "            response = requests.get(self.api_url, headers=self.headers, params=querystring)\n",
        "            response.raise_for_status()  # Raise an exception for bad status codes (e.g., 400, 401)\n",
        "\n",
        "            # Return the response as a JSON string\n",
        "            return str(response.json())\n",
        "\n",
        "        except requests.RequestException as e:\n",
        "            return f\"Error scraping LinkedIn profile '{linkedin_url}': {str(e)}\"\n",
        "        except Exception as e:\n",
        "            return f\"Error processing request: {str(e)}\""
      ],
      "metadata": {
        "id": "DDy8GUg7hUyM"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import Tool\n",
        "import requests\n",
        "\n",
        "class PDFCreatorTool(Tool):\n",
        "    name = \"pdf_creator\"\n",
        "    description = \"Creates a PDF from HTML content using the YakPDF API from RapidAPI.\"\n",
        "\n",
        "    inputs = {\n",
        "        \"html_content\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"The HTML content to convert into a PDF.\"\n",
        "        },\n",
        "        \"pdf_options\": {\n",
        "            \"type\": \"object\",\n",
        "            \"description\": \"Optional PDF formatting options (e.g., {'format': 'A4', 'scale': 1}).\",\n",
        "            \"default\": None,\n",
        "            \"nullable\": True  # Allow None as a valid value\n",
        "        }\n",
        "    }\n",
        "\n",
        "    output_type = \"string\"\n",
        "    def __init__(self, api_key , **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.api_url = \"https://yakpdf.p.rapidapi.com/pdf\"\n",
        "        self.headers = {\n",
        "            \"x-rapidapi-key\": api_key,\n",
        "            \"x-rapidapi-host\": \"yakpdf.p.rapidapi.com\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, html_content: str, pdf_options: dict = None):\n",
        "        \"\"\"\n",
        "        Create a PDF from the provided HTML content using the YakPDF API.\n",
        "\n",
        "        Args:\n",
        "            html_content (str): The HTML content to convert.\n",
        "            pdf_options (dict, optional): PDF formatting options (e.g., {'format': 'A4'}).\n",
        "\n",
        "        Returns:\n",
        "            str: The PDF response as a string or an error message.\n",
        "        \"\"\"\n",
        "        # Construct the payload\n",
        "        payload = {\n",
        "            \"source\": {\"html\": html_content},\n",
        "            \"pdf\": {\n",
        "                \"format\": \"A4\",\n",
        "                \"scale\": 1,\n",
        "                \"printBackground\": True\n",
        "            },\n",
        "            \"wait\": {\n",
        "                \"for\": \"navigation\",\n",
        "                \"waitUntil\": \"load\",\n",
        "                \"timeout\": 2500\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Update PDF options if provided\n",
        "        if pdf_options:\n",
        "            payload[\"pdf\"].update(pdf_options)\n",
        "\n",
        "        try:\n",
        "            # Send the POST request to the YakPDF API\n",
        "            response = requests.post(self.api_url, json=payload, headers=self.headers)\n",
        "            response.raise_for_status()  # Raise an exception for bad status codes (e.g., 400, 401)\n",
        "            pdf_data = response.content\n",
        "\n",
        "            with open(\"/content/output.pdf\", \"wb\") as f:\n",
        "              f.write(pdf_data)\n",
        "\n",
        "            print(\"PDF file saved as output.pdf\")\n",
        "\n",
        "            # Return the response content as a string (PDF binary data)\n",
        "            return \"PDF file saved as output.pdf \"\n",
        "\n",
        "        except requests.RequestException as e:\n",
        "            return f\"Error creating PDF: {str(e)}\"\n",
        "        except Exception as e:\n",
        "            return f\"Error processing request: {str(e)}\""
      ],
      "metadata": {
        "id": "bnMpeICunpmL"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import Tool , CodeAgent\n",
        "from groq import Groq\n",
        "\n",
        "class GroqChatTool(Tool):\n",
        "    name = \"groq_chat\"\n",
        "    description = \"Generates text completions using the Groq API based on a user prompt.\"\n",
        "\n",
        "    inputs = {\n",
        "\n",
        "        \"html_content\": {\n",
        "            \"type\": \"string\",\n",
        "            \"description\": \"the content that have to convert to ui \",\n",
        "            \"default\": None,\n",
        "            \"nullable\": True  # Allow None as a valid value\n",
        "        }\n",
        "    }\n",
        "\n",
        "    output_type = \"string\"\n",
        "    def __init__(self, api_key , **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.client = Groq(api_key=api_key)\n",
        "        self.model = model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, html_content : str = \"you are a helpful assistant\"):\n",
        "        \"\"\"\n",
        "        Generate a text completion using the Groq API.\n",
        "\n",
        "        Args:\n",
        "            html_content (str): The system message to guide the assistant's behavior.\n",
        "\n",
        "        Returns:\n",
        "            str: A highly complete html css ui fo given content\n",
        "        \"\"\"\n",
        "        # Construct the messages list\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"ceate a good html css design from the text and only return code \"},\n",
        "            {\"role\": \"user\", \"content\": html_content }\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            # Send the request to the Groq API\n",
        "            chat_completion = self.client.chat.completions.create(\n",
        "                messages=messages,\n",
        "                model=self.model,\n",
        "                max_completion_tokens=8092,\n",
        "                top_p=1,  # Default from your example\n",
        "                stop=None,  # Default from your example\n",
        "                stream=False  # Default from your example\n",
        "            )\n",
        "\n",
        "            # Extract and return the completion\n",
        "            return chat_completion.choices[0].message.content\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error generating completion with Groq API: {str(e)}\""
      ],
      "metadata": {
        "id": "kSinaylCtBOT"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linked_scaper = LinkedInProfileScraperTool(api_key = \"Rapid_api_key\")\n",
        "\n",
        "linked_resume = CodeAgent(\n",
        "    tools=[linked_scaper],\n",
        "    model=model,\n",
        "    max_steps=10,\n",
        "    additional_authorized_imports=['datetime', 'statistics', 'time', 'stat', 'queue', 're', 'unicodedata', 'collections', 'math',\n",
        "'random', 'itertools'],\n",
        "    name=\"linkedin_resume\",\n",
        "    description=\"creates a ell defined 2 page resume from the extracted data\",\n",
        ")"
      ],
      "metadata": {
        "id": "-gbEcOTrnKMg"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_creation_tool = PDFCreatorTool(api_key = \"Rapid_api_key\")\n",
        "\n",
        "pdf_creation = CodeAgent(\n",
        "    tools=[pdf_creation_tool],\n",
        "    model=model,\n",
        "    max_steps=10,\n",
        "    additional_authorized_imports=['datetime', 'statistics', 'time', 'stat', 'queue', 're', 'unicodedata', 'collections', 'math',\n",
        "'random', 'itertools'],\n",
        "    name=\"html_to_pdf\",\n",
        "    description=\"convert a html code to pdf and save the pdf \",\n",
        ")"
      ],
      "metadata": {
        "id": "NlrFuL5-oSLN"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_to_ui = GroqChatTool(api_key = \"Groq_api_key\" )\n",
        "resumetxt_to_html_css = CodeAgent(\n",
        "    tools=[resume_to_ui],\n",
        "    model=model,\n",
        "    max_steps=10,\n",
        "    additional_authorized_imports=['datetime', 'statistics', 'time', 'stat', 'queue', 're', 'unicodedata', 'collections', 'math',\n",
        "'random', 'itertools'],\n",
        "    name=\"resume_html_css\",\n",
        "    description=\"convert a string to highly stylish html css ui \",\n",
        ")"
      ],
      "metadata": {
        "id": "Bt5jHH60or6M"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manager_agent = CodeAgent(\n",
        "    tools=[],\n",
        "    model=model,\n",
        "    managed_agents=[linked_resume, pdf_creation, resumetxt_to_html_css],\n",
        "    max_steps=10,\n",
        "    additional_authorized_imports=['datetime', 'stat', 're', 'math', 'collections', 'itertools', 'statistics', 'time', 'queue',\n",
        "'unicodedata', 'random'],\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "DpyjJwVapBlC"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manager_agent.run('create resume fo a developer from linkedin profile  https://www.linkedin.com/in/linkedin-profile-link-username/ then convert it to html and then to pdf ')"
      ],
      "metadata": {
        "id": "GZKlII_gpPM4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
